# ğŸ­ Gesture-Controlled Image Filters using OpenCV & MediaPipe ğŸ¨

## ğŸ“Œ Overview
This project implements **real-time hand gesture recognition** to apply different image filters using a webcam.  
The system detects **six different hand gestures** and applies corresponding filters to the webcam feed.

### **Supported Gestures & Filters:**
| Gesture | Effect |
|---------|--------|
| âœ‹ **Open Palm** | No filter (Default) |
| âœŠ **Fist** | Grayscale |
| âœŒï¸ **Peace Sign** | Sepia |
| ğŸ‘ **Thumbs Up** | Blur |
| â˜ï¸ **Pointing Finger** | Edge Detection |
| ğŸ‘Œ **OK Sign** | Cartoon Effect |

---

## ğŸ”§ **Installation**
Ensure you have Python installed (>=3.7). Then, install the required dependencies:

```bash
pip install opencv-python mediapipe numpy torch torchvision scikit-learn pickle-mixin
```

Alternatively, install from the `requirements.txt` file:

```bash
pip install -r requirements.txt
```

---

## ğŸš€ **Project Structure**
```plaintext
gesture-controlled-filters/
â”‚â€” collect_data.py       # Collects hand keypoints for model training
â”‚â€” train_model.py        # Trains a gesture classification model
â”‚â€” apply_filters.py      # Runs real-time gesture detection & filtering
â”‚â€” gesture_data.pkl      # Saved dataset of hand keypoints (generated by collect_data.py)
â”‚â€” gesture_model.pth     # Trained PyTorch model (generated by train_model.py)
â”‚â€” requirements.txt      # Required dependencies
â”‚â€” README.md             # Project documentation
```

---

## ğŸ¥ **How to Use**
### 1ï¸âƒ£ **Collect Gesture Data**
Run this script to collect **200 frames per gesture** using MediaPipe Hands:

```bash
python collect_data.py
```
ğŸ›  **Instructions:**
- Press **Enter** to start collecting for each gesture.
- Hold the gesture steady and slightly vary angles.
- Captures **200 samples per gesture**.
- Press **'q'** to quit data collection.

### 2ï¸âƒ£ **Train the Gesture Classification Model**
Once data is collected, train the **MLP neural network**:

```bash
python train_model.py
```
ğŸ’ª This will generate `gesture_model.pth`, which is the trained model.

### 3ï¸âƒ£ **Run Real-Time Gesture Recognition & Filtering**
```bash
python apply_filters.py
```
ğŸ‘€ The webcam will display **both the original frame and the filtered frame**.  
Try **different gestures** to see filters change in real time!

---

## ğŸ›  **Troubleshooting**
### âŒ **No webcam feed appears**
- Ensure your **camera is enabled** in system settings.
- Try running with `cv2.VideoCapture(1)` if using an external webcam.

### âŒ **No gestures detected**
- Increase `min_detection_confidence` in `collect_data.py`:
  ```python
  hands = mp.solutions.hands.Hands(min_detection_confidence=0.3)
  ```
- Ensure **good lighting** and **clear background**.

### âŒ **Filters not applying correctly**
- Print model predictions:
  ```python
  print(f"Detected gesture: {gesture}")
  ```
- If misclassification occurs, **collect more data** and **retrain the model**.

### âŒ **Cartoon filter is not showing correctly**
- Adjust `cv2.adaptiveThreshold()` in `cartoon()`:
  ```python
  edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,
                                cv2.THRESH_BINARY, blockSize=9, C=9)
  ```

---

## ğŸ”¥ **Upcoming Improvements**
ğŸ”¹ Add **multiple hand support**  
ğŸ”¹ Improve **gesture accuracy** with more training data  
ğŸ”¹ Convert project into a **Streamlit app for a GUI**  

---

## ğŸ‘¨â€ğŸ’» **Author**
Developed by **[Your Name]**  
GitHub: [Your GitHub Profile](https://github.com/YourGitHubUsername)  

---

## â­ **Contributing**
Feel free to **fork this repo** and submit pull requests! Suggestions and improvements are always welcome.  

ğŸš€ **Happy Coding!** ğŸ¬âœ¨

